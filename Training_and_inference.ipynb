{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rdiazrincon/SLEAP_workshop/blob/master/Training_and_inference.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K5xp-A8Oc80Q"
      },
      "source": [
        "# Training and Inference with SLEAP\n",
        "\n",
        "This notebook shows you how to run training and inference on your own data from SLEAP using the command-line interface."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yX9noEb8m8re"
      },
      "source": [
        "# Installation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C5WL10cao-sc"
      },
      "source": [
        "SLEAP uses Tensorflow 2.x. However, since it's included in Colab we don't need to install it. \n",
        "\n",
        "For this part of the workshop we will use the GPU, so let's check that it's available. If the GPU is available executing the next line will return `/device:GPU:0`. \n",
        "\n",
        "If you see otherwise, please go to \"Runtime\" -> \"Change runtime type\" and select GPU under \"Hardware accelerator\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "9I12Lk6TKZnn",
        "outputId": "cb76a399-e6e7-452e-9fb3-6891f3dc7819"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/device:GPU:0'"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pMjYpcVFqWgV"
      },
      "source": [
        "Now let's use `pip` to install SLEAP from PyPI.\n",
        "\n",
        "Note: This installation method should also work on other Linux machines, such as an HPC cluster, or on any system where you aren't planning to use a GPU. To use a GPU on a Windows machine you'll need to install using `conda`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DUfnkxMtLcK3",
        "outputId": "d0640675-4573-44f7-8140-51b0c58e7fdc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: sleap==1.2.6 in /usr/local/lib/python3.7/dist-packages (1.2.6)\n",
            "Requirement already satisfied: imageio<=2.15.0 in /usr/local/lib/python3.7/dist-packages (from sleap==1.2.6) (2.9.0)\n",
            "Requirement already satisfied: scikit-learn==1.0.* in /usr/local/lib/python3.7/dist-packages (from sleap==1.2.6) (1.0.2)\n",
            "Requirement already satisfied: rich==10.16.1 in /usr/local/lib/python3.7/dist-packages (from sleap==1.2.6) (10.16.1)\n",
            "Requirement already satisfied: certifi<=2021.10.8,>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from sleap==1.2.6) (2021.10.8)\n",
            "Requirement already satisfied: cattrs==1.1.1 in /usr/local/lib/python3.7/dist-packages (from sleap==1.2.6) (1.1.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from sleap==1.2.6) (2.6.3)\n",
            "Requirement already satisfied: tensorflow<2.9.0,>=2.6.3 in /usr/local/lib/python3.7/dist-packages (from sleap==1.2.6) (2.8.2+zzzcolab20220719082949)\n",
            "Requirement already satisfied: attrs==21.2.0 in /usr/local/lib/python3.7/dist-packages (from sleap==1.2.6) (21.2.0)\n",
            "Requirement already satisfied: PySide2<=5.14.1,>=5.13.2 in /usr/local/lib/python3.7/dist-packages (from sleap==1.2.6) (5.14.1)\n",
            "Requirement already satisfied: pykalman==0.9.5 in /usr/local/lib/python3.7/dist-packages (from sleap==1.2.6) (0.9.5)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.7/dist-packages (from sleap==1.2.6) (0.11.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from sleap==1.2.6) (5.4.8)\n",
            "Requirement already satisfied: segmentation-models==1.0.1 in /usr/local/lib/python3.7/dist-packages (from sleap==1.2.6) (1.0.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from sleap==1.2.6) (1.3.5)\n",
            "Requirement already satisfied: numpy<=1.21.5,>=1.19.5 in /usr/local/lib/python3.7/dist-packages (from sleap==1.2.6) (1.21.5)\n",
            "Requirement already satisfied: scipy<=1.7.3,>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from sleap==1.2.6) (1.7.3)\n",
            "Requirement already satisfied: jsmin in /usr/local/lib/python3.7/dist-packages (from sleap==1.2.6) (3.0.1)\n",
            "Requirement already satisfied: opencv-python-headless<=4.5.5.62,>=4.2.0.34 in /usr/local/lib/python3.7/dist-packages (from sleap==1.2.6) (4.5.5.62)\n",
            "Requirement already satisfied: pynwb in /usr/local/lib/python3.7/dist-packages (from sleap==1.2.6) (2.1.0)\n",
            "Requirement already satisfied: pyzmq in /usr/local/lib/python3.7/dist-packages (from sleap==1.2.6) (23.2.0)\n",
            "Requirement already satisfied: qimage2ndarray<=1.8.3,>=1.8.2 in /usr/local/lib/python3.7/dist-packages (from sleap==1.2.6) (1.8.3)\n",
            "Requirement already satisfied: python-rapidjson in /usr/local/lib/python3.7/dist-packages (from sleap==1.2.6) (1.8)\n",
            "Requirement already satisfied: scikit-video in /usr/local/lib/python3.7/dist-packages (from sleap==1.2.6) (1.1.11)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from sleap==1.2.6) (3.13)\n",
            "Requirement already satisfied: jsonpickle==1.2 in /usr/local/lib/python3.7/dist-packages (from sleap==1.2.6) (1.2)\n",
            "Requirement already satisfied: imgstore==0.2.9 in /usr/local/lib/python3.7/dist-packages (from sleap==1.2.6) (0.2.9)\n",
            "Requirement already satisfied: ndx-pose in /usr/local/lib/python3.7/dist-packages (from sleap==1.2.6) (0.1.1)\n",
            "Requirement already satisfied: h5py<=3.6.0,>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from sleap==1.2.6) (3.1.0)\n",
            "Requirement already satisfied: imgaug==0.4.0 in /usr/local/lib/python3.7/dist-packages (from sleap==1.2.6) (0.4.0)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.7/dist-packages (from sleap==1.2.6) (0.18.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from imgaug==0.4.0->sleap==1.2.6) (1.15.0)\n",
            "Requirement already satisfied: Shapely in /usr/local/lib/python3.7/dist-packages (from imgaug==0.4.0->sleap==1.2.6) (1.8.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from imgaug==0.4.0->sleap==1.2.6) (3.2.2)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from imgaug==0.4.0->sleap==1.2.6) (4.6.0.66)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from imgaug==0.4.0->sleap==1.2.6) (7.1.2)\n",
            "Requirement already satisfied: tzlocal in /usr/local/lib/python3.7/dist-packages (from imgstore==0.2.9->sleap==1.2.6) (1.5.1)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from imgstore==0.2.9->sleap==1.2.6) (2022.1)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from imgstore==0.2.9->sleap==1.2.6) (2.8.2)\n",
            "Requirement already satisfied: commonmark<0.10.0,>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from rich==10.16.1->sleap==1.2.6) (0.9.1)\n",
            "Requirement already satisfied: colorama<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from rich==10.16.1->sleap==1.2.6) (0.4.5)\n",
            "Requirement already satisfied: typing-extensions<5.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from rich==10.16.1->sleap==1.2.6) (4.1.1)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.6.0 in /usr/local/lib/python3.7/dist-packages (from rich==10.16.1->sleap==1.2.6) (2.6.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==1.0.*->sleap==1.2.6) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==1.0.*->sleap==1.2.6) (1.1.0)\n",
            "Requirement already satisfied: efficientnet==1.0.0 in /usr/local/lib/python3.7/dist-packages (from segmentation-models==1.0.1->sleap==1.2.6) (1.0.0)\n",
            "Requirement already satisfied: keras-applications<=1.0.8,>=1.0.7 in /usr/local/lib/python3.7/dist-packages (from segmentation-models==1.0.1->sleap==1.2.6) (1.0.8)\n",
            "Requirement already satisfied: image-classifiers==1.0.0 in /usr/local/lib/python3.7/dist-packages (from segmentation-models==1.0.1->sleap==1.2.6) (1.0.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py<=3.6.0,>=3.1.0->sleap==1.2.6) (1.5.2)\n",
            "Requirement already satisfied: shiboken2==5.14.1 in /usr/local/lib/python3.7/dist-packages (from PySide2<=5.14.1,>=5.13.2->sleap==1.2.6) (5.14.1)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image->sleap==1.2.6) (1.3.0)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image->sleap==1.2.6) (2021.11.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug==0.4.0->sleap==1.2.6) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug==0.4.0->sleap==1.2.6) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug==0.4.0->sleap==1.2.6) (1.4.4)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9.0,>=2.6.3->sleap==1.2.6) (14.0.6)\n",
            "Requirement already satisfied: tensorflow-estimator<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9.0,>=2.6.3->sleap==1.2.6) (2.8.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9.0,>=2.6.3->sleap==1.2.6) (3.17.3)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9.0,>=2.6.3->sleap==1.2.6) (1.6.3)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9.0,>=2.6.3->sleap==1.2.6) (2.8.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9.0,>=2.6.3->sleap==1.2.6) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9.0,>=2.6.3->sleap==1.2.6) (3.3.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9.0,>=2.6.3->sleap==1.2.6) (57.4.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9.0,>=2.6.3->sleap==1.2.6) (1.14.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9.0,>=2.6.3->sleap==1.2.6) (1.1.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9.0,>=2.6.3->sleap==1.2.6) (1.47.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9.0,>=2.6.3->sleap==1.2.6) (0.26.0)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9.0,>=2.6.3->sleap==1.2.6) (2.8.0)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9.0,>=2.6.3->sleap==1.2.6) (2.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9.0,>=2.6.3->sleap==1.2.6) (1.2.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9.0,>=2.6.3->sleap==1.2.6) (1.1.0)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9.0,>=2.6.3->sleap==1.2.6) (0.5.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow<2.9.0,>=2.6.3->sleap==1.2.6) (0.37.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9.0,>=2.6.3->sleap==1.2.6) (3.4.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9.0,>=2.6.3->sleap==1.2.6) (1.35.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9.0,>=2.6.3->sleap==1.2.6) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9.0,>=2.6.3->sleap==1.2.6) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9.0,>=2.6.3->sleap==1.2.6) (1.8.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9.0,>=2.6.3->sleap==1.2.6) (0.6.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9.0,>=2.6.3->sleap==1.2.6) (2.23.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow<2.9.0,>=2.6.3->sleap==1.2.6) (4.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow<2.9.0,>=2.6.3->sleap==1.2.6) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow<2.9.0,>=2.6.3->sleap==1.2.6) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow<2.9.0,>=2.6.3->sleap==1.2.6) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow<2.9.0,>=2.6.3->sleap==1.2.6) (4.12.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow<2.9.0,>=2.6.3->sleap==1.2.6) (3.8.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow<2.9.0,>=2.6.3->sleap==1.2.6) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow<2.9.0,>=2.6.3->sleap==1.2.6) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow<2.9.0,>=2.6.3->sleap==1.2.6) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow<2.9.0,>=2.6.3->sleap==1.2.6) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow<2.9.0,>=2.6.3->sleap==1.2.6) (3.2.0)\n",
            "Requirement already satisfied: hdmf<4,>=2.5.6 in /usr/local/lib/python3.7/dist-packages (from ndx-pose->sleap==1.2.6) (3.3.2)\n",
            "Requirement already satisfied: ruamel.yaml<1,>=0.16 in /usr/local/lib/python3.7/dist-packages (from hdmf<4,>=2.5.6->ndx-pose->sleap==1.2.6) (0.17.21)\n",
            "Requirement already satisfied: jsonschema<5,>=2.6.0 in /usr/local/lib/python3.7/dist-packages (from hdmf<4,>=2.5.6->ndx-pose->sleap==1.2.6) (4.3.3)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema<5,>=2.6.0->hdmf<4,>=2.5.6->ndx-pose->sleap==1.2.6) (0.18.1)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema<5,>=2.6.0->hdmf<4,>=2.5.6->ndx-pose->sleap==1.2.6) (5.9.0)\n",
            "Requirement already satisfied: ruamel.yaml.clib>=0.2.6 in /usr/local/lib/python3.7/dist-packages (from ruamel.yaml<1,>=0.16->hdmf<4,>=2.5.6->ndx-pose->sleap==1.2.6) (0.2.6)\n"
          ]
        }
      ],
      "source": [
        "!pip install sleap==1.2.6"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iq7jrgUksLtR"
      },
      "source": [
        "## Getting your training data into Colab\n",
        "\n",
        "You'll need to get your training data into Colab. So let's get the data from the workshop's [repo](https://github.com/rdiazrincon/SLEAP_workshop)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KQhv_gsdJzaq"
      },
      "source": [
        "The training package contains both labeled data as well as the labeled images which will be used for training. One advantage to training packages is that it doesn't depend on paths to other files (i.e., videos) to be messed up when you copy your project to another volume. See [this guide](https://sleap.ai/guides/training-package.html) for exporting a training package from SLEAP.\n",
        "\n",
        "**Important**: For this demo, we will use the file `data.pkg.slp`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zu_jZlBkND51"
      },
      "source": [
        "# Getting the data\n",
        "\n",
        "The next cell downloads the data needed to run training and inference. \n",
        "\n",
        "**Important:** If you wish to run training and inference with your own data, modify lines 1 and 2 of the next cell. When you do, make sure you are using the same variables or change them as you wish.\n",
        "\n",
        "The first line downloads the behavioral video. The second line downloads the training package. The next lines download the bottom up, top down and centroid training profiles. \n",
        "\n",
        "You can find more info about the models [here](https://sleap.ai/guides/choosing-models.html#choosing-models). \n",
        "\n",
        "These training profiles can also be downloaded from the [official repository](https://github.com/talmolab/sleap/tree/develop/sleap/training_profiles).\n",
        "\n",
        "If your data comes from a shared dropbox link look at the commented lines in the next cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# If your video or training package comes from a shared link in dropbox do the following:\n",
        "# Make sure you have ?dl=1 at the end of the link\n",
        "\n",
        "# curl -L -o video.AVI https://www.dropbox.com/s/randomuser/video.avi?dl=1\n",
        "# curl -L -o data.pkg.slp https://www.dropbox.com/s/randomuser/training_package.pkg.slp?dl=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9umui-gI2rBz",
        "outputId": "50302dcc-8b70-4005-ab68-000eda032ab7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2022-08-05 01:46:58--  https://github.com/rdiazrincon/SLEAP_Data/blob/master/videos/video.AVI?raw=true\n",
            "Resolving github.com (github.com)... 140.82.114.3\n",
            "Connecting to github.com (github.com)|140.82.114.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github.com/rdiazrincon/SLEAP_Data/raw/master/videos/video.AVI [following]\n",
            "--2022-08-05 01:46:58--  https://github.com/rdiazrincon/SLEAP_Data/raw/master/videos/video.AVI\n",
            "Reusing existing connection to github.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://media.githubusercontent.com/media/rdiazrincon/SLEAP_Data/master/videos/video.AVI [following]\n",
            "--2022-08-05 01:46:58--  https://media.githubusercontent.com/media/rdiazrincon/SLEAP_Data/master/videos/video.AVI\n",
            "Resolving media.githubusercontent.com (media.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to media.githubusercontent.com (media.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 811157572 (774M) [video/msvideo]\n",
            "Saving to: ‘video.AVI’\n",
            "\n",
            "video.AVI           100%[===================>] 773.58M   230MB/s    in 3.4s    \n",
            "\n",
            "2022-08-05 01:47:11 (226 MB/s) - ‘video.AVI’ saved [811157572/811157572]\n",
            "\n",
            "--2022-08-05 01:47:11--  https://github.com/rdiazrincon/SLEAP_workshop/blob/master/examples/data.pkg.slp?raw=true\n",
            "Resolving github.com (github.com)... 140.82.114.3\n",
            "Connecting to github.com (github.com)|140.82.114.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github.com/rdiazrincon/SLEAP_workshop/raw/master/examples/data.pkg.slp [following]\n",
            "--2022-08-05 01:47:11--  https://github.com/rdiazrincon/SLEAP_workshop/raw/master/examples/data.pkg.slp\n",
            "Reusing existing connection to github.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/rdiazrincon/SLEAP_workshop/master/examples/data.pkg.slp [following]\n",
            "--2022-08-05 01:47:11--  https://raw.githubusercontent.com/rdiazrincon/SLEAP_workshop/master/examples/data.pkg.slp\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 33448238 (32M) [application/octet-stream]\n",
            "Saving to: ‘data.pkg.slp’\n",
            "\n",
            "data.pkg.slp        100%[===================>]  31.90M   183MB/s    in 0.2s    \n",
            "\n",
            "2022-08-05 01:47:12 (183 MB/s) - ‘data.pkg.slp’ saved [33448238/33448238]\n",
            "\n",
            "--2022-08-05 01:47:12--  https://github.com/rdiazrincon/SLEAP_Data/blob/master/training_profiles/baseline_medium_rf.bottomup.json?raw=true\n",
            "Resolving github.com (github.com)... 140.82.113.4\n",
            "Connecting to github.com (github.com)|140.82.113.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github.com/rdiazrincon/SLEAP_Data/raw/master/training_profiles/baseline_medium_rf.bottomup.json [following]\n",
            "--2022-08-05 01:47:12--  https://github.com/rdiazrincon/SLEAP_Data/raw/master/training_profiles/baseline_medium_rf.bottomup.json\n",
            "Reusing existing connection to github.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/rdiazrincon/SLEAP_Data/master/training_profiles/baseline_medium_rf.bottomup.json [following]\n",
            "--2022-08-05 01:47:12--  https://raw.githubusercontent.com/rdiazrincon/SLEAP_Data/master/training_profiles/baseline_medium_rf.bottomup.json\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4639 (4.5K) [text/plain]\n",
            "Saving to: ‘baseline_medium_rf.bottomup.json’\n",
            "\n",
            "baseline_medium_rf. 100%[===================>]   4.53K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-08-05 01:47:12 (57.5 MB/s) - ‘baseline_medium_rf.bottomup.json’ saved [4639/4639]\n",
            "\n",
            "--2022-08-05 01:47:12--  https://github.com/rdiazrincon/SLEAP_Data/blob/master/training_profiles/baseline_medium_rf.topdown.json?raw=true\n",
            "Resolving github.com (github.com)... 140.82.114.4\n",
            "Connecting to github.com (github.com)|140.82.114.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github.com/rdiazrincon/SLEAP_Data/raw/master/training_profiles/baseline_medium_rf.topdown.json [following]\n",
            "--2022-08-05 01:47:13--  https://github.com/rdiazrincon/SLEAP_Data/raw/master/training_profiles/baseline_medium_rf.topdown.json\n",
            "Reusing existing connection to github.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/rdiazrincon/SLEAP_Data/master/training_profiles/baseline_medium_rf.topdown.json [following]\n",
            "--2022-08-05 01:47:13--  https://raw.githubusercontent.com/rdiazrincon/SLEAP_Data/master/training_profiles/baseline_medium_rf.topdown.json\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4522 (4.4K) [text/plain]\n",
            "Saving to: ‘baseline_medium_rf.topdown.json’\n",
            "\n",
            "baseline_medium_rf. 100%[===================>]   4.42K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-08-05 01:47:13 (58.9 MB/s) - ‘baseline_medium_rf.topdown.json’ saved [4522/4522]\n",
            "\n",
            "--2022-08-05 01:47:13--  https://github.com/rdiazrincon/SLEAP_Data/blob/master/training_profiles/baseline.centroid.json?raw=true\n",
            "Resolving github.com (github.com)... 140.82.114.3\n",
            "Connecting to github.com (github.com)|140.82.114.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github.com/rdiazrincon/SLEAP_Data/raw/master/training_profiles/baseline.centroid.json [following]\n",
            "--2022-08-05 01:47:13--  https://github.com/rdiazrincon/SLEAP_Data/raw/master/training_profiles/baseline.centroid.json\n",
            "Reusing existing connection to github.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/rdiazrincon/SLEAP_Data/master/training_profiles/baseline.centroid.json [following]\n",
            "--2022-08-05 01:47:13--  https://raw.githubusercontent.com/rdiazrincon/SLEAP_Data/master/training_profiles/baseline.centroid.json\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4477 (4.4K) [text/plain]\n",
            "Saving to: ‘baseline.centroid.json’\n",
            "\n",
            "baseline.centroid.j 100%[===================>]   4.37K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-08-05 01:47:13 (54.3 MB/s) - ‘baseline.centroid.json’ saved [4477/4477]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!wget -O video.AVI https://github.com/rdiazrincon/SLEAP_Data/blob/master/videos/video.AVI?raw=true # Behavioral Video\n",
        "!wget -O data.pkg.slp https://github.com/rdiazrincon/SLEAP_workshop/blob/master/examples/data.pkg.slp?raw=true # Training package\n",
        "!wget -O baseline_medium_rf.bottomup.json https://github.com/rdiazrincon/SLEAP_Data/blob/master/training_profiles/baseline_medium_rf.bottomup.json?raw=true # Bottom Up model\n",
        "!wget -O baseline_medium_rf.topdown.json https://github.com/rdiazrincon/SLEAP_Data/blob/master/training_profiles/baseline_medium_rf.topdown.json?raw=true # Top down model\n",
        "!wget -O baseline.centroid.json https://github.com/rdiazrincon/SLEAP_Data/blob/master/training_profiles/baseline.centroid.json?raw=true # Centroid model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xZ-sr67av5uu"
      },
      "source": [
        "## Training\n",
        "\n",
        "Now you're ready to train a model! We'll use the command-line interface for training, and train a model for confidence maps using the default **training profile**. The training profile determines the model architecture, the learning rate for training, and other training hyperparameters.\n",
        "\n",
        "When you start running this cell, you'll see the training parameters listed and then you'll see the training and validation loss for each training epoch.\n",
        "\n",
        "If you're happy with the validation loss you see for an epoch during training, you're welcome to stop training by clicking the stop button next to the notebook cell running training. The version of the model with the lowest validation loss is saved during training, and that's what will be used for inference. If you don't stop training, it will run for 200 epochs, or until validation loss fails to improve for some number of epochs (controlled by the `early_stopping` parameter in the training profile).\n",
        "\n",
        "**Important**: If your training package isn't named `data.pkg.slp`, you'll need to adjust the name below."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CDfwXAZoND6O"
      },
      "source": [
        "In the next line we run training using the bottom up model\n",
        "\n",
        "**Important:** Training can take between 15 and 25 minutes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QKf6qzMqNBUi",
        "outputId": "270f0769-1a10-4445-ec7e-37384b27c97a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:numexpr.utils:NumExpr defaulting to 2 threads.\n",
            "INFO:sleap.nn.training:Versions:\n",
            "SLEAP: 1.2.6\n",
            "TensorFlow: 2.8.2\n",
            "Numpy: 1.21.5\n",
            "Python: 3.7.13\n",
            "OS: Linux-5.4.188+-x86_64-with-Ubuntu-18.04-bionic\n",
            "INFO:sleap.nn.training:Training labels file: data.pkg.slp\n",
            "INFO:sleap.nn.training:Training profile: baseline_medium_rf.bottomup.json\n",
            "INFO:sleap.nn.training:\n",
            "INFO:sleap.nn.training:Arguments:\n",
            "INFO:sleap.nn.training:{\n",
            "    \"training_job_path\": \"baseline_medium_rf.bottomup.json\",\n",
            "    \"labels_path\": \"data.pkg.slp\",\n",
            "    \"video_paths\": [\n",
            "        \"\"\n",
            "    ],\n",
            "    \"val_labels\": null,\n",
            "    \"test_labels\": null,\n",
            "    \"tensorboard\": false,\n",
            "    \"save_viz\": false,\n",
            "    \"zmq\": false,\n",
            "    \"run_name\": \"\",\n",
            "    \"prefix\": \"\",\n",
            "    \"suffix\": \"\",\n",
            "    \"cpu\": false,\n",
            "    \"first_gpu\": false,\n",
            "    \"last_gpu\": false,\n",
            "    \"gpu\": 0\n",
            "}\n",
            "INFO:sleap.nn.training:\n",
            "INFO:sleap.nn.training:Training job:\n",
            "INFO:sleap.nn.training:{\n",
            "    \"data\": {\n",
            "        \"labels\": {\n",
            "            \"training_labels\": null,\n",
            "            \"validation_labels\": null,\n",
            "            \"validation_fraction\": 0.1,\n",
            "            \"test_labels\": null,\n",
            "            \"split_by_inds\": false,\n",
            "            \"training_inds\": null,\n",
            "            \"validation_inds\": null,\n",
            "            \"test_inds\": null,\n",
            "            \"search_path_hints\": [],\n",
            "            \"skeletons\": []\n",
            "        },\n",
            "        \"preprocessing\": {\n",
            "            \"ensure_rgb\": false,\n",
            "            \"ensure_grayscale\": false,\n",
            "            \"imagenet_mode\": null,\n",
            "            \"input_scaling\": 1.0,\n",
            "            \"pad_to_stride\": null,\n",
            "            \"resize_and_pad_to_target\": true,\n",
            "            \"target_height\": null,\n",
            "            \"target_width\": null\n",
            "        },\n",
            "        \"instance_cropping\": {\n",
            "            \"center_on_part\": null,\n",
            "            \"crop_size\": null,\n",
            "            \"crop_size_detection_padding\": 16\n",
            "        }\n",
            "    },\n",
            "    \"model\": {\n",
            "        \"backbone\": {\n",
            "            \"leap\": null,\n",
            "            \"unet\": {\n",
            "                \"stem_stride\": null,\n",
            "                \"max_stride\": 32,\n",
            "                \"output_stride\": 4,\n",
            "                \"filters\": 16,\n",
            "                \"filters_rate\": 2.0,\n",
            "                \"middle_block\": true,\n",
            "                \"up_interpolate\": true,\n",
            "                \"stacks\": 1\n",
            "            },\n",
            "            \"hourglass\": null,\n",
            "            \"resnet\": null,\n",
            "            \"pretrained_encoder\": null\n",
            "        },\n",
            "        \"heads\": {\n",
            "            \"single_instance\": null,\n",
            "            \"centroid\": null,\n",
            "            \"centered_instance\": null,\n",
            "            \"multi_instance\": {\n",
            "                \"confmaps\": {\n",
            "                    \"part_names\": null,\n",
            "                    \"sigma\": 2.5,\n",
            "                    \"output_stride\": 4,\n",
            "                    \"loss_weight\": 1.0,\n",
            "                    \"offset_refinement\": false\n",
            "                },\n",
            "                \"pafs\": {\n",
            "                    \"edges\": null,\n",
            "                    \"sigma\": 75.0,\n",
            "                    \"output_stride\": 8,\n",
            "                    \"loss_weight\": 1.0\n",
            "                }\n",
            "            },\n",
            "            \"multi_class_bottomup\": null,\n",
            "            \"multi_class_topdown\": null\n",
            "        }\n",
            "    },\n",
            "    \"optimization\": {\n",
            "        \"preload_data\": true,\n",
            "        \"augmentation_config\": {\n",
            "            \"rotate\": true,\n",
            "            \"rotation_min_angle\": -15.0,\n",
            "            \"rotation_max_angle\": 15.0,\n",
            "            \"translate\": false,\n",
            "            \"translate_min\": -5,\n",
            "            \"translate_max\": 5,\n",
            "            \"scale\": false,\n",
            "            \"scale_min\": 0.9,\n",
            "            \"scale_max\": 1.1,\n",
            "            \"uniform_noise\": false,\n",
            "            \"uniform_noise_min_val\": 0.0,\n",
            "            \"uniform_noise_max_val\": 10.0,\n",
            "            \"gaussian_noise\": false,\n",
            "            \"gaussian_noise_mean\": 5.0,\n",
            "            \"gaussian_noise_stddev\": 1.0,\n",
            "            \"contrast\": false,\n",
            "            \"contrast_min_gamma\": 0.5,\n",
            "            \"contrast_max_gamma\": 2.0,\n",
            "            \"brightness\": false,\n",
            "            \"brightness_min_val\": 0.0,\n",
            "            \"brightness_max_val\": 10.0,\n",
            "            \"random_crop\": false,\n",
            "            \"random_crop_height\": 256,\n",
            "            \"random_crop_width\": 256,\n",
            "            \"random_flip\": false,\n",
            "            \"flip_horizontal\": true\n",
            "        },\n",
            "        \"online_shuffling\": true,\n",
            "        \"shuffle_buffer_size\": 128,\n",
            "        \"prefetch\": true,\n",
            "        \"batch_size\": 4,\n",
            "        \"batches_per_epoch\": null,\n",
            "        \"min_batches_per_epoch\": 200,\n",
            "        \"val_batches_per_epoch\": null,\n",
            "        \"min_val_batches_per_epoch\": 10,\n",
            "        \"epochs\": 200,\n",
            "        \"optimizer\": \"adam\",\n",
            "        \"initial_learning_rate\": 0.0001,\n",
            "        \"learning_rate_schedule\": {\n",
            "            \"reduce_on_plateau\": true,\n",
            "            \"reduction_factor\": 0.5,\n",
            "            \"plateau_min_delta\": 1e-08,\n",
            "            \"plateau_patience\": 8,\n",
            "            \"plateau_cooldown\": 3,\n",
            "            \"min_learning_rate\": 1e-08\n",
            "        },\n",
            "        \"hard_keypoint_mining\": {\n",
            "            \"online_mining\": false,\n",
            "            \"hard_to_easy_ratio\": 2.0,\n",
            "            \"min_hard_keypoints\": 2,\n",
            "            \"max_hard_keypoints\": null,\n",
            "            \"loss_scale\": 5.0\n",
            "        },\n",
            "        \"early_stopping\": {\n",
            "            \"stop_training_on_plateau\": true,\n",
            "            \"plateau_min_delta\": 1e-08,\n",
            "            \"plateau_patience\": 10\n",
            "        }\n",
            "    },\n",
            "    \"outputs\": {\n",
            "        \"save_outputs\": true,\n",
            "        \"run_name\": \"baseline_medium_rf.bottomup\",\n",
            "        \"run_name_prefix\": \"\",\n",
            "        \"run_name_suffix\": null,\n",
            "        \"runs_folder\": \"models\",\n",
            "        \"tags\": [],\n",
            "        \"save_visualizations\": true,\n",
            "        \"delete_viz_images\": true,\n",
            "        \"zip_outputs\": false,\n",
            "        \"log_to_csv\": true,\n",
            "        \"checkpointing\": {\n",
            "            \"initial_model\": false,\n",
            "            \"best_model\": true,\n",
            "            \"every_epoch\": false,\n",
            "            \"latest_model\": false,\n",
            "            \"final_model\": false\n",
            "        },\n",
            "        \"tensorboard\": {\n",
            "            \"write_logs\": false,\n",
            "            \"loss_frequency\": \"epoch\",\n",
            "            \"architecture_graph\": false,\n",
            "            \"profile_graph\": false,\n",
            "            \"visualizations\": true\n",
            "        },\n",
            "        \"zmq\": {\n",
            "            \"subscribe_to_controller\": false,\n",
            "            \"controller_address\": \"tcp://127.0.0.1:9000\",\n",
            "            \"controller_polling_timeout\": 10,\n",
            "            \"publish_updates\": false,\n",
            "            \"publish_address\": \"tcp://127.0.0.1:9001\"\n",
            "        }\n",
            "    },\n",
            "    \"name\": \"\",\n",
            "    \"description\": \"\",\n",
            "    \"sleap_version\": \"1.2.6\",\n",
            "    \"filename\": \"baseline_medium_rf.bottomup.json\"\n",
            "}\n",
            "INFO:sleap.nn.training:\n",
            "INFO:sleap.nn.training:Using GPU 0 for acceleration.\n",
            "INFO:sleap.nn.training:Disabled GPU memory pre-allocation.\n",
            "INFO:sleap.nn.training:System:\n",
            "GPUs: 1/1 available\n",
            "  Device: /physical_device:GPU:0\n",
            "         Available: True\n",
            "        Initalized: False\n",
            "     Memory growth: True\n",
            "INFO:sleap.nn.training:\n",
            "INFO:sleap.nn.training:Initializing trainer...\n",
            "INFO:sleap.nn.training:Loading training labels from: data.pkg.slp\n",
            "INFO:sleap.nn.training:Creating training and validation splits from validation fraction: 0.1\n",
            "INFO:sleap.nn.training:  Splits: Training = 82 / Validation = 9.\n",
            "INFO:sleap.nn.training:Setting up for training...\n",
            "INFO:sleap.nn.training:Setting up pipeline builders...\n",
            "INFO:sleap.nn.training:Setting up model...\n",
            "INFO:sleap.nn.training:Building test pipeline...\n",
            "INFO:sleap.nn.training:Loaded test example. [2.176s]\n",
            "INFO:sleap.nn.training:  Input shape: (480, 640, 3)\n",
            "INFO:sleap.nn.training:Created Keras model.\n",
            "INFO:sleap.nn.training:  Backbone: UNet(stacks=1, filters=16, filters_rate=2.0, kernel_size=3, stem_kernel_size=7, convs_per_block=2, stem_blocks=0, down_blocks=5, middle_block=True, up_blocks=3, up_interpolate=True, block_contraction=False)\n",
            "INFO:sleap.nn.training:  Max stride: 32\n",
            "INFO:sleap.nn.training:  Parameters: 7,818,146\n",
            "INFO:sleap.nn.training:  Heads: \n",
            "INFO:sleap.nn.training:    [0] = MultiInstanceConfmapsHead(part_names=['left_ear', 'right_ear', 'nose', 'tail_base', 'thorax', 'forehead'], sigma=2.5, output_stride=4, loss_weight=1.0)\n",
            "INFO:sleap.nn.training:    [1] = PartAffinityFieldsHead(edges=[('nose', 'forehead'), ('forehead', 'left_ear'), ('forehead', 'right_ear'), ('left_ear', 'thorax'), ('right_ear', 'thorax'), ('thorax', 'tail_base')], sigma=75.0, output_stride=8, loss_weight=1.0)\n",
            "INFO:sleap.nn.training:  Outputs: \n",
            "INFO:sleap.nn.training:    [0] = KerasTensor(type_spec=TensorSpec(shape=(None, 120, 160, 6), dtype=tf.float32, name=None), name='MultiInstanceConfmapsHead/BiasAdd:0', description=\"created by layer 'MultiInstanceConfmapsHead'\")\n",
            "INFO:sleap.nn.training:    [1] = KerasTensor(type_spec=TensorSpec(shape=(None, 60, 80, 12), dtype=tf.float32, name=None), name='PartAffinityFieldsHead/BiasAdd:0', description=\"created by layer 'PartAffinityFieldsHead'\")\n",
            "INFO:sleap.nn.training:Setting up data pipelines...\n",
            "INFO:sleap.nn.training:Training set: n = 82\n",
            "INFO:sleap.nn.training:Validation set: n = 9\n",
            "INFO:sleap.nn.training:Setting up optimization...\n",
            "INFO:sleap.nn.training:  Learning rate schedule: LearningRateScheduleConfig(reduce_on_plateau=True, reduction_factor=0.5, plateau_min_delta=1e-08, plateau_patience=8, plateau_cooldown=3, min_learning_rate=1e-08)\n",
            "INFO:sleap.nn.training:  Early stopping: EarlyStoppingConfig(stop_training_on_plateau=True, plateau_min_delta=1e-08, plateau_patience=10)\n",
            "INFO:sleap.nn.training:Setting up outputs...\n",
            "INFO:sleap.nn.training:Created run path: models/baseline_medium_rf.bottomup\n",
            "INFO:sleap.nn.training:Setting up visualization...\n",
            "2022-08-05 01:48:42.990959: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -33 } dim { size: -34 } dim { size: -35 } dim { size: 1 } } } inputs { dtype: DT_FLOAT shape { dim { size: -2 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -2 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla T4\" frequency: 1590 num_cores: 40 environment { key: \"architecture\" value: \"7.5\" } environment { key: \"cuda\" value: \"11010\" } environment { key: \"cudnn\" value: \"8005\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 65536 memory_size: 14150270976 bandwidth: 320064000 } outputs { dtype: DT_FLOAT shape { dim { size: -2 } dim { size: -36 } dim { size: -37 } dim { size: 1 } } }\n",
            "2022-08-05 01:48:44.132211: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -33 } dim { size: -34 } dim { size: -35 } dim { size: 1 } } } inputs { dtype: DT_FLOAT shape { dim { size: -2 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -2 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla T4\" frequency: 1590 num_cores: 40 environment { key: \"architecture\" value: \"7.5\" } environment { key: \"cuda\" value: \"11010\" } environment { key: \"cudnn\" value: \"8005\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 65536 memory_size: 14150270976 bandwidth: 320064000 } outputs { dtype: DT_FLOAT shape { dim { size: -2 } dim { size: -36 } dim { size: -37 } dim { size: 1 } } }\n",
            "Unable to use Qt backend for matplotlib. This probably means Qt is running headless.\n",
            "INFO:sleap.nn.training:Finished trainer set up. [6.0s]\n",
            "INFO:sleap.nn.training:Creating tf.data.Datasets for training data generation...\n",
            "INFO:sleap.nn.training:Finished creating training datasets. [4.9s]\n",
            "INFO:sleap.nn.training:Starting training loop...\n",
            "Epoch 1/200\n",
            "200/200 - 59s - loss: 0.0045 - MultiInstanceConfmapsHead_loss: 0.0016 - PartAffinityFieldsHead_loss: 0.0029 - val_loss: 0.0037 - val_MultiInstanceConfmapsHead_loss: 0.0013 - val_PartAffinityFieldsHead_loss: 0.0023 - lr: 1.0000e-04 - 59s/epoch - 295ms/step\n",
            "Epoch 2/200\n",
            "200/200 - 41s - loss: 0.0028 - MultiInstanceConfmapsHead_loss: 9.8397e-04 - PartAffinityFieldsHead_loss: 0.0019 - val_loss: 0.0028 - val_MultiInstanceConfmapsHead_loss: 9.6884e-04 - val_PartAffinityFieldsHead_loss: 0.0018 - lr: 1.0000e-04 - 41s/epoch - 205ms/step\n",
            "Epoch 3/200\n",
            "200/200 - 43s - loss: 0.0021 - MultiInstanceConfmapsHead_loss: 7.1724e-04 - PartAffinityFieldsHead_loss: 0.0014 - val_loss: 0.0023 - val_MultiInstanceConfmapsHead_loss: 7.8537e-04 - val_PartAffinityFieldsHead_loss: 0.0015 - lr: 1.0000e-04 - 43s/epoch - 217ms/step\n",
            "Epoch 4/200\n",
            "200/200 - 44s - loss: 0.0016 - MultiInstanceConfmapsHead_loss: 5.4433e-04 - PartAffinityFieldsHead_loss: 0.0011 - val_loss: 0.0020 - val_MultiInstanceConfmapsHead_loss: 6.8359e-04 - val_PartAffinityFieldsHead_loss: 0.0014 - lr: 1.0000e-04 - 44s/epoch - 219ms/step\n",
            "Epoch 5/200\n",
            "200/200 - 41s - loss: 0.0013 - MultiInstanceConfmapsHead_loss: 4.2018e-04 - PartAffinityFieldsHead_loss: 8.9402e-04 - val_loss: 0.0017 - val_MultiInstanceConfmapsHead_loss: 5.7984e-04 - val_PartAffinityFieldsHead_loss: 0.0011 - lr: 1.0000e-04 - 41s/epoch - 204ms/step\n",
            "Epoch 6/200\n",
            "200/200 - 42s - loss: 0.0011 - MultiInstanceConfmapsHead_loss: 3.3025e-04 - PartAffinityFieldsHead_loss: 7.3713e-04 - val_loss: 0.0018 - val_MultiInstanceConfmapsHead_loss: 5.8227e-04 - val_PartAffinityFieldsHead_loss: 0.0012 - lr: 1.0000e-04 - 42s/epoch - 210ms/step\n",
            "Epoch 7/200\n",
            "200/200 - 40s - loss: 8.6943e-04 - MultiInstanceConfmapsHead_loss: 2.6109e-04 - PartAffinityFieldsHead_loss: 6.0834e-04 - val_loss: 0.0015 - val_MultiInstanceConfmapsHead_loss: 4.9178e-04 - val_PartAffinityFieldsHead_loss: 0.0010 - lr: 1.0000e-04 - 40s/epoch - 201ms/step\n",
            "Epoch 8/200\n",
            "200/200 - 42s - loss: 7.3123e-04 - MultiInstanceConfmapsHead_loss: 2.1185e-04 - PartAffinityFieldsHead_loss: 5.1938e-04 - val_loss: 0.0016 - val_MultiInstanceConfmapsHead_loss: 5.1036e-04 - val_PartAffinityFieldsHead_loss: 0.0011 - lr: 1.0000e-04 - 42s/epoch - 211ms/step\n",
            "Epoch 9/200\n",
            "200/200 - 40s - loss: 6.1416e-04 - MultiInstanceConfmapsHead_loss: 1.7280e-04 - PartAffinityFieldsHead_loss: 4.4136e-04 - val_loss: 0.0018 - val_MultiInstanceConfmapsHead_loss: 5.5459e-04 - val_PartAffinityFieldsHead_loss: 0.0012 - lr: 1.0000e-04 - 40s/epoch - 199ms/step\n",
            "Epoch 10/200\n",
            "200/200 - 43s - loss: 5.7446e-04 - MultiInstanceConfmapsHead_loss: 1.6283e-04 - PartAffinityFieldsHead_loss: 4.1163e-04 - val_loss: 0.0016 - val_MultiInstanceConfmapsHead_loss: 5.5216e-04 - val_PartAffinityFieldsHead_loss: 0.0011 - lr: 1.0000e-04 - 43s/epoch - 214ms/step\n",
            "Epoch 11/200\n",
            "200/200 - 40s - loss: 5.0263e-04 - MultiInstanceConfmapsHead_loss: 1.3813e-04 - PartAffinityFieldsHead_loss: 3.6450e-04 - val_loss: 0.0017 - val_MultiInstanceConfmapsHead_loss: 5.2953e-04 - val_PartAffinityFieldsHead_loss: 0.0011 - lr: 1.0000e-04 - 40s/epoch - 198ms/step\n",
            "Epoch 12/200\n",
            "200/200 - 40s - loss: 4.4412e-04 - MultiInstanceConfmapsHead_loss: 1.1891e-04 - PartAffinityFieldsHead_loss: 3.2521e-04 - val_loss: 0.0016 - val_MultiInstanceConfmapsHead_loss: 4.9200e-04 - val_PartAffinityFieldsHead_loss: 0.0011 - lr: 1.0000e-04 - 40s/epoch - 202ms/step\n",
            "Epoch 13/200\n",
            "200/200 - 41s - loss: 4.0617e-04 - MultiInstanceConfmapsHead_loss: 1.0838e-04 - PartAffinityFieldsHead_loss: 2.9779e-04 - val_loss: 0.0016 - val_MultiInstanceConfmapsHead_loss: 5.0907e-04 - val_PartAffinityFieldsHead_loss: 0.0011 - lr: 1.0000e-04 - 41s/epoch - 206ms/step\n",
            "Epoch 14/200\n",
            "200/200 - 40s - loss: 3.8463e-04 - MultiInstanceConfmapsHead_loss: 1.0233e-04 - PartAffinityFieldsHead_loss: 2.8230e-04 - val_loss: 0.0016 - val_MultiInstanceConfmapsHead_loss: 4.9204e-04 - val_PartAffinityFieldsHead_loss: 0.0011 - lr: 1.0000e-04 - 40s/epoch - 201ms/step\n",
            "Epoch 15/200\n",
            "\n",
            "Epoch 15: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
            "200/200 - 42s - loss: 3.5234e-04 - MultiInstanceConfmapsHead_loss: 9.2947e-05 - PartAffinityFieldsHead_loss: 2.5940e-04 - val_loss: 0.0016 - val_MultiInstanceConfmapsHead_loss: 5.1845e-04 - val_PartAffinityFieldsHead_loss: 0.0011 - lr: 1.0000e-04 - 42s/epoch - 209ms/step\n",
            "Epoch 16/200\n",
            "200/200 - 42s - loss: 2.6881e-04 - MultiInstanceConfmapsHead_loss: 6.3824e-05 - PartAffinityFieldsHead_loss: 2.0498e-04 - val_loss: 0.0016 - val_MultiInstanceConfmapsHead_loss: 5.1067e-04 - val_PartAffinityFieldsHead_loss: 0.0011 - lr: 5.0000e-05 - 42s/epoch - 211ms/step\n",
            "Epoch 17/200\n",
            "200/200 - 39s - loss: 2.4738e-04 - MultiInstanceConfmapsHead_loss: 5.7121e-05 - PartAffinityFieldsHead_loss: 1.9026e-04 - val_loss: 0.0015 - val_MultiInstanceConfmapsHead_loss: 4.9244e-04 - val_PartAffinityFieldsHead_loss: 0.0010 - lr: 5.0000e-05 - 39s/epoch - 196ms/step\n",
            "Epoch 18/200\n",
            "200/200 - 40s - loss: 2.3708e-04 - MultiInstanceConfmapsHead_loss: 5.4220e-05 - PartAffinityFieldsHead_loss: 1.8286e-04 - val_loss: 0.0016 - val_MultiInstanceConfmapsHead_loss: 4.9728e-04 - val_PartAffinityFieldsHead_loss: 0.0011 - lr: 5.0000e-05 - 40s/epoch - 199ms/step\n",
            "Epoch 19/200\n",
            "200/200 - 41s - loss: 2.2356e-04 - MultiInstanceConfmapsHead_loss: 5.0149e-05 - PartAffinityFieldsHead_loss: 1.7341e-04 - val_loss: 0.0015 - val_MultiInstanceConfmapsHead_loss: 4.8684e-04 - val_PartAffinityFieldsHead_loss: 0.0011 - lr: 5.0000e-05 - 41s/epoch - 203ms/step\n",
            "Epoch 20/200\n",
            "200/200 - 43s - loss: 2.1426e-04 - MultiInstanceConfmapsHead_loss: 4.8026e-05 - PartAffinityFieldsHead_loss: 1.6624e-04 - val_loss: 0.0016 - val_MultiInstanceConfmapsHead_loss: 4.9555e-04 - val_PartAffinityFieldsHead_loss: 0.0011 - lr: 5.0000e-05 - 43s/epoch - 213ms/step\n",
            "Epoch 21/200\n",
            "200/200 - 39s - loss: 2.1158e-04 - MultiInstanceConfmapsHead_loss: 4.7356e-05 - PartAffinityFieldsHead_loss: 1.6423e-04 - val_loss: 0.0016 - val_MultiInstanceConfmapsHead_loss: 4.9909e-04 - val_PartAffinityFieldsHead_loss: 0.0011 - lr: 5.0000e-05 - 39s/epoch - 193ms/step\n",
            "Epoch 22/200\n",
            "200/200 - 42s - loss: 2.0121e-04 - MultiInstanceConfmapsHead_loss: 4.4478e-05 - PartAffinityFieldsHead_loss: 1.5673e-04 - val_loss: 0.0015 - val_MultiInstanceConfmapsHead_loss: 4.6530e-04 - val_PartAffinityFieldsHead_loss: 0.0010 - lr: 5.0000e-05 - 42s/epoch - 208ms/step\n",
            "Epoch 23/200\n",
            "200/200 - 40s - loss: 1.9650e-04 - MultiInstanceConfmapsHead_loss: 4.3454e-05 - PartAffinityFieldsHead_loss: 1.5304e-04 - val_loss: 0.0017 - val_MultiInstanceConfmapsHead_loss: 5.4085e-04 - val_PartAffinityFieldsHead_loss: 0.0012 - lr: 5.0000e-05 - 40s/epoch - 201ms/step\n",
            "Epoch 24/200\n",
            "200/200 - 41s - loss: 1.8630e-04 - MultiInstanceConfmapsHead_loss: 4.0589e-05 - PartAffinityFieldsHead_loss: 1.4571e-04 - val_loss: 0.0017 - val_MultiInstanceConfmapsHead_loss: 5.3876e-04 - val_PartAffinityFieldsHead_loss: 0.0012 - lr: 5.0000e-05 - 41s/epoch - 203ms/step\n",
            "Epoch 25/200\n",
            "200/200 - 43s - loss: 1.8166e-04 - MultiInstanceConfmapsHead_loss: 3.9775e-05 - PartAffinityFieldsHead_loss: 1.4189e-04 - val_loss: 0.0018 - val_MultiInstanceConfmapsHead_loss: 5.6397e-04 - val_PartAffinityFieldsHead_loss: 0.0012 - lr: 5.0000e-05 - 43s/epoch - 213ms/step\n",
            "Epoch 26/200\n",
            "200/200 - 40s - loss: 1.7523e-04 - MultiInstanceConfmapsHead_loss: 3.8005e-05 - PartAffinityFieldsHead_loss: 1.3723e-04 - val_loss: 0.0017 - val_MultiInstanceConfmapsHead_loss: 5.2130e-04 - val_PartAffinityFieldsHead_loss: 0.0011 - lr: 5.0000e-05 - 40s/epoch - 200ms/step\n",
            "Epoch 27/200\n",
            "200/200 - 40s - loss: 1.7035e-04 - MultiInstanceConfmapsHead_loss: 3.6931e-05 - PartAffinityFieldsHead_loss: 1.3342e-04 - val_loss: 0.0018 - val_MultiInstanceConfmapsHead_loss: 5.8080e-04 - val_PartAffinityFieldsHead_loss: 0.0012 - lr: 5.0000e-05 - 40s/epoch - 202ms/step\n",
            "Epoch 28/200\n",
            "200/200 - 41s - loss: 1.6548e-04 - MultiInstanceConfmapsHead_loss: 3.5658e-05 - PartAffinityFieldsHead_loss: 1.2982e-04 - val_loss: 0.0017 - val_MultiInstanceConfmapsHead_loss: 5.3693e-04 - val_PartAffinityFieldsHead_loss: 0.0012 - lr: 5.0000e-05 - 41s/epoch - 203ms/step\n",
            "Epoch 29/200\n",
            "200/200 - 43s - loss: 1.5860e-04 - MultiInstanceConfmapsHead_loss: 3.3748e-05 - PartAffinityFieldsHead_loss: 1.2485e-04 - val_loss: 0.0017 - val_MultiInstanceConfmapsHead_loss: 5.4353e-04 - val_PartAffinityFieldsHead_loss: 0.0012 - lr: 5.0000e-05 - 43s/epoch - 213ms/step\n",
            "Epoch 30/200\n",
            "\n",
            "Epoch 30: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
            "200/200 - 39s - loss: 1.5591e-04 - MultiInstanceConfmapsHead_loss: 3.3090e-05 - PartAffinityFieldsHead_loss: 1.2282e-04 - val_loss: 0.0016 - val_MultiInstanceConfmapsHead_loss: 5.2057e-04 - val_PartAffinityFieldsHead_loss: 0.0011 - lr: 5.0000e-05 - 39s/epoch - 193ms/step\n",
            "Epoch 31/200\n",
            "200/200 - 41s - loss: 1.3846e-04 - MultiInstanceConfmapsHead_loss: 2.7655e-05 - PartAffinityFieldsHead_loss: 1.1080e-04 - val_loss: 0.0016 - val_MultiInstanceConfmapsHead_loss: 5.1024e-04 - val_PartAffinityFieldsHead_loss: 0.0011 - lr: 2.5000e-05 - 41s/epoch - 206ms/step\n",
            "Epoch 32/200\n",
            "200/200 - 41s - loss: 1.3398e-04 - MultiInstanceConfmapsHead_loss: 2.6555e-05 - PartAffinityFieldsHead_loss: 1.0743e-04 - val_loss: 0.0017 - val_MultiInstanceConfmapsHead_loss: 5.4207e-04 - val_PartAffinityFieldsHead_loss: 0.0012 - lr: 2.5000e-05 - 41s/epoch - 204ms/step\n",
            "Epoch 32: early stopping\n",
            "INFO:sleap.nn.training:Finished training loop. [22.2 min]\n",
            "INFO:sleap.nn.training:Deleting visualization directory: models/baseline_medium_rf.bottomup/viz\n",
            "INFO:sleap.nn.training:Saving evaluation metrics to model folder...\n",
            "\u001b[2KPredicting... \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m  0%\u001b[0m ETA: \u001b[36m-:--:--\u001b[0m \u001b[31m?\u001b[0m2022-08-05 02:11:05.758053: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -65 } dim { size: -66 } dim { size: -67 } dim { size: 1 } } } inputs { dtype: DT_FLOAT shape { dim { size: -2 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -2 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla T4\" frequency: 1590 num_cores: 40 environment { key: \"architecture\" value: \"7.5\" } environment { key: \"cuda\" value: \"11010\" } environment { key: \"cudnn\" value: \"8005\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 65536 memory_size: 14150270976 bandwidth: 320064000 } outputs { dtype: DT_FLOAT shape { dim { size: -2 } dim { size: -68 } dim { size: -69 } dim { size: 1 } } }\n",
            "\u001b[2KPredicting... \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[35m 98%\u001b[0m ETA: \u001b[36m0:00:01\u001b[0m \u001b[31m26.0 FPS\u001b[0m2022-08-05 02:11:12.598825: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -65 } dim { size: -66 } dim { size: -67 } dim { size: 1 } } } inputs { dtype: DT_FLOAT shape { dim { size: -2 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -2 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla T4\" frequency: 1590 num_cores: 40 environment { key: \"architecture\" value: \"7.5\" } environment { key: \"cuda\" value: \"11010\" } environment { key: \"cudnn\" value: \"8005\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 65536 memory_size: 14150270976 bandwidth: 320064000 } outputs { dtype: DT_FLOAT shape { dim { size: -2 } dim { size: -68 } dim { size: -69 } dim { size: 1 } } }\n",
            "\u001b[2KPredicting... \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m ETA: \u001b[36m0:00:00\u001b[0m \u001b[31m4.4 FPS\u001b[0m\n",
            "\u001b[?25hINFO:sleap.nn.evals:Saved predictions: models/baseline_medium_rf.bottomup/labels_pr.train.slp\n",
            "INFO:sleap.nn.evals:Saved metrics: models/baseline_medium_rf.bottomup/metrics.train.npz\n",
            "INFO:sleap.nn.evals:OKS mAP: 0.932834\n",
            "\u001b[2KPredicting... \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m  0%\u001b[0m ETA: \u001b[36m-:--:--\u001b[0m \u001b[31m?\u001b[0m2022-08-05 02:11:24.539738: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -65 } dim { size: -66 } dim { size: -67 } dim { size: 1 } } } inputs { dtype: DT_FLOAT shape { dim { size: -2 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -2 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla T4\" frequency: 1590 num_cores: 40 environment { key: \"architecture\" value: \"7.5\" } environment { key: \"cuda\" value: \"11010\" } environment { key: \"cudnn\" value: \"8005\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 65536 memory_size: 14150270976 bandwidth: 320064000 } outputs { dtype: DT_FLOAT shape { dim { size: -2 } dim { size: -68 } dim { size: -69 } dim { size: 1 } } }\n",
            "\u001b[2KPredicting... \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━\u001b[0m \u001b[35m 89%\u001b[0m ETA: \u001b[36m0:00:01\u001b[0m \u001b[31m30.8 FPS\u001b[0m2022-08-05 02:11:27.903374: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -65 } dim { size: -66 } dim { size: -67 } dim { size: 1 } } } inputs { dtype: DT_FLOAT shape { dim { size: -2 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -2 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla T4\" frequency: 1590 num_cores: 40 environment { key: \"architecture\" value: \"7.5\" } environment { key: \"cuda\" value: \"11010\" } environment { key: \"cudnn\" value: \"8005\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 65536 memory_size: 14150270976 bandwidth: 320064000 } outputs { dtype: DT_FLOAT shape { dim { size: -2 } dim { size: -68 } dim { size: -69 } dim { size: 1 } } }\n",
            "\u001b[2KPredicting... \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m ETA: \u001b[36m0:00:00\u001b[0m \u001b[31m1.5 FPS\u001b[0m\n",
            "\u001b[?25hINFO:sleap.nn.evals:Saved predictions: models/baseline_medium_rf.bottomup/labels_pr.val.slp\n",
            "INFO:sleap.nn.evals:Saved metrics: models/baseline_medium_rf.bottomup/metrics.val.npz\n",
            "INFO:sleap.nn.evals:OKS mAP: 0.381549\n"
          ]
        }
      ],
      "source": [
        "!sleap-train baseline_medium_rf.bottomup.json data.pkg.slp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "whOf8PaFxYbt"
      },
      "source": [
        "Once training finishes, you'll have a trained model for confidence maps. There will be a `models/` directory inside your root directory and inside this there will be a `baseline_medium_rf.bottomup directory`. \n",
        "\n",
        "This `baseline_medium_rf.bottomup` directory contains all the files SLEAP needs to use this model. You can copy it to a local drive if you want to use it for running inference from the SLEAP GUI, copy it to a network drive if you want to run inference from an HPC cluster, or just leave it here if you want to run inference on Colab... as we'll do below."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q7JUp9P840qB"
      },
      "source": [
        "## Training other models\n",
        "\n",
        "The **bottomup** model you trained above can be used for \"bottom up\" inference. You can also train a **centroid** model and a **centered instance** model for \"top down\" inference. See [here](https://sleap.ai/#getting-started-with-sleap) for more information about these two different approaches.\n",
        "\n",
        "Here's how to train centroid and centered instance models using the default training settings:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WZVftKcJ46jU"
      },
      "outputs": [],
      "source": [
        "!sleap-train baseline_medium_rf.topdown.json data.pkg.slp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DsPTDnkW49-5"
      },
      "outputs": [],
      "source": [
        "!sleap-train baseline.centroid.json data.pkg.slp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nIsKUX661xFK"
      },
      "source": [
        "# Inference\n",
        "\n",
        "At this point you should have SLEAP installed and trained models saved. If you've been working through the notebook, you should have a `models` subdirectory inside your current working directory. Let's take a look:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "01HDohE5upwQ",
        "outputId": "f8798da4-8d04-454a-9a85-f5e0dfaac681"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "baseline_medium_rf.bottomup\n"
          ]
        }
      ],
      "source": [
        "!ls models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mf-MsD7fv5Wy"
      },
      "source": [
        "## Inference parameters\n",
        "\n",
        "One important option when running inference is whether (and how) you want to track instance identities. If you omit `--tracking.tracker flow` then the identities will not be tracked. Tracking methods/options are explained [here](https://sleap.ai/guides/proofreading.html#tracking-methods).\n",
        "\n",
        "You can see all of the command-line arguments by calling `sleap-track` with the `--help` argument, like so:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6hh4ogd9wtxP",
        "outputId": "5cda0291-3511-4fcf-8a4d-f4ec0ae29fbf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:numexpr.utils:NumExpr defaulting to 2 threads.\n",
            "Started inference at: 2022-08-05 02:13:22.859183\n",
            "usage: sleap-track [-h] [-m MODELS] [--frames FRAMES] [--only-labeled-frames]\n",
            "                   [--only-suggested-frames] [-o OUTPUT] [--no-empty-frames]\n",
            "                   [--verbosity {none,rich,json}]\n",
            "                   [--video.dataset VIDEO.DATASET]\n",
            "                   [--video.input_format VIDEO.INPUT_FORMAT]\n",
            "                   [--cpu | --first-gpu | --last-gpu | --gpu GPU]\n",
            "                   [--max_edge_length_ratio MAX_EDGE_LENGTH_RATIO]\n",
            "                   [--dist_penalty_weight DIST_PENALTY_WEIGHT]\n",
            "                   [--batch_size BATCH_SIZE] [--open-in-gui]\n",
            "                   [--peak_threshold PEAK_THRESHOLD]\n",
            "                   [--tracking.tracker TRACKING.TRACKER]\n",
            "                   [--tracking.target_instance_count TRACKING.TARGET_INSTANCE_COUNT]\n",
            "                   [--tracking.pre_cull_to_target TRACKING.PRE_CULL_TO_TARGET]\n",
            "                   [--tracking.pre_cull_iou_threshold TRACKING.PRE_CULL_IOU_THRESHOLD]\n",
            "                   [--tracking.post_connect_single_breaks TRACKING.POST_CONNECT_SINGLE_BREAKS]\n",
            "                   [--tracking.clean_instance_count TRACKING.CLEAN_INSTANCE_COUNT]\n",
            "                   [--tracking.clean_iou_threshold TRACKING.CLEAN_IOU_THRESHOLD]\n",
            "                   [--tracking.similarity TRACKING.SIMILARITY]\n",
            "                   [--tracking.match TRACKING.MATCH]\n",
            "                   [--tracking.track_window TRACKING.TRACK_WINDOW]\n",
            "                   [--tracking.min_new_track_points TRACKING.MIN_NEW_TRACK_POINTS]\n",
            "                   [--tracking.min_match_points TRACKING.MIN_MATCH_POINTS]\n",
            "                   [--tracking.img_scale TRACKING.IMG_SCALE]\n",
            "                   [--tracking.of_window_size TRACKING.OF_WINDOW_SIZE]\n",
            "                   [--tracking.of_max_levels TRACKING.OF_MAX_LEVELS]\n",
            "                   [--tracking.kf_node_indices TRACKING.KF_NODE_INDICES]\n",
            "                   [--tracking.kf_init_frame_count TRACKING.KF_INIT_FRAME_COUNT]\n",
            "                   [data_path]\n",
            "\n",
            "positional arguments:\n",
            "  data_path             Path to data to predict on. This can be a labels\n",
            "                        (.slp) file or any supported video format.\n",
            "\n",
            "optional arguments:\n",
            "  -h, --help            show this help message and exit\n",
            "  -m MODELS, --model MODELS\n",
            "                        Path to trained model directory (with\n",
            "                        training_config.json). Multiple models can be\n",
            "                        specified, each preceded by --model.\n",
            "  --frames FRAMES       List of frames to predict when running on a video. Can\n",
            "                        be specified as a comma separated list (e.g. 1,2,3) or\n",
            "                        a range separated by hyphen (e.g., 1-3, for 1,2,3). If\n",
            "                        not provided, defaults to predicting on the entire\n",
            "                        video.\n",
            "  --only-labeled-frames\n",
            "                        Only run inference on user labeled frames when running\n",
            "                        on labels dataset. This is useful for generating\n",
            "                        predictions to compare against ground truth.\n",
            "  --only-suggested-frames\n",
            "                        Only run inference on unlabeled suggested frames when\n",
            "                        running on labels dataset. This is useful for\n",
            "                        generating predictions for initialization during\n",
            "                        labeling.\n",
            "  -o OUTPUT, --output OUTPUT\n",
            "                        The output filename to use for the predicted data. If\n",
            "                        not provided, defaults to\n",
            "                        '[data_path].predictions.slp'.\n",
            "  --no-empty-frames     Clear any empty frames that did not have any detected\n",
            "                        instances before saving to output.\n",
            "  --verbosity {none,rich,json}\n",
            "                        Verbosity of inference progress reporting. 'none' does\n",
            "                        not output anything during inference, 'rich' displays\n",
            "                        an updating progress bar, and 'json' outputs the\n",
            "                        progress as a JSON encoded response to the console.\n",
            "  --video.dataset VIDEO.DATASET\n",
            "                        The dataset for HDF5 videos.\n",
            "  --video.input_format VIDEO.INPUT_FORMAT\n",
            "                        The input_format for HDF5 videos.\n",
            "  --cpu                 Run inference only on CPU. If not specified, will use\n",
            "                        available GPU.\n",
            "  --first-gpu           Run inference on the first GPU, if available.\n",
            "  --last-gpu            Run inference on the last GPU, if available.\n",
            "  --gpu GPU             Run inference on the i-th GPU specified.\n",
            "  --max_edge_length_ratio MAX_EDGE_LENGTH_RATIO\n",
            "                        The maximum expected length of a connected pair of\n",
            "                        points as a fraction of the image size. Candidate\n",
            "                        connections longer than this length will be penalized\n",
            "                        during matching. Only applies to bottom-up (PAF)\n",
            "                        models.\n",
            "  --dist_penalty_weight DIST_PENALTY_WEIGHT\n",
            "                        A coefficient to scale weight of the distance penalty.\n",
            "                        Set to values greater than 1.0 to enforce the distance\n",
            "                        penalty more strictly. Only applies to bottom-up (PAF)\n",
            "                        models.\n",
            "  --batch_size BATCH_SIZE\n",
            "                        Number of frames to predict at a time. Larger values\n",
            "                        result in faster inference speeds, but require more\n",
            "                        memory.\n",
            "  --open-in-gui         Open the resulting predictions in the GUI when\n",
            "                        finished.\n",
            "  --peak_threshold PEAK_THRESHOLD\n",
            "                        Minimum confidence map value to consider a peak as\n",
            "                        valid.\n",
            "  --tracking.tracker TRACKING.TRACKER\n",
            "                        Options: simple, flow, None (default: None)\n",
            "  --tracking.target_instance_count TRACKING.TARGET_INSTANCE_COUNT\n",
            "                        Target number of instances to track per frame.\n",
            "                        (default: 0)\n",
            "  --tracking.pre_cull_to_target TRACKING.PRE_CULL_TO_TARGET\n",
            "                        If non-zero and target_instance_count is also non-\n",
            "                        zero, then cull instances over target count per frame\n",
            "                        *before* tracking. (default: 0)\n",
            "  --tracking.pre_cull_iou_threshold TRACKING.PRE_CULL_IOU_THRESHOLD\n",
            "                        If non-zero and pre_cull_to_target also set, then use\n",
            "                        IOU threshold to remove overlapping instances over\n",
            "                        count *before* tracking. (default: 0)\n",
            "  --tracking.post_connect_single_breaks TRACKING.POST_CONNECT_SINGLE_BREAKS\n",
            "                        If non-zero and target_instance_count is also non-\n",
            "                        zero, then connect track breaks when exactly one track\n",
            "                        is lost and exactly one track is spawned in frame.\n",
            "                        (default: 0)\n",
            "  --tracking.clean_instance_count TRACKING.CLEAN_INSTANCE_COUNT\n",
            "                        Target number of instances to clean *after* tracking.\n",
            "                        (default: 0)\n",
            "  --tracking.clean_iou_threshold TRACKING.CLEAN_IOU_THRESHOLD\n",
            "                        IOU to use when culling instances *after* tracking.\n",
            "                        (default: 0)\n",
            "  --tracking.similarity TRACKING.SIMILARITY\n",
            "                        Options: instance, centroid, iou (default: instance)\n",
            "  --tracking.match TRACKING.MATCH\n",
            "                        Options: hungarian, greedy (default: greedy)\n",
            "  --tracking.track_window TRACKING.TRACK_WINDOW\n",
            "                        How many frames back to look for matches (default: 5)\n",
            "  --tracking.min_new_track_points TRACKING.MIN_NEW_TRACK_POINTS\n",
            "                        Minimum number of instance points for spawning new\n",
            "                        track (default: 0)\n",
            "  --tracking.min_match_points TRACKING.MIN_MATCH_POINTS\n",
            "                        Minimum points for match candidates (default: 0)\n",
            "  --tracking.img_scale TRACKING.IMG_SCALE\n",
            "                        For optical-flow: Image scale (default: 1.0)\n",
            "  --tracking.of_window_size TRACKING.OF_WINDOW_SIZE\n",
            "                        For optical-flow: Optical flow window size to consider\n",
            "                        at each pyramid (default: 21)\n",
            "  --tracking.of_max_levels TRACKING.OF_MAX_LEVELS\n",
            "                        For optical-flow: Number of pyramid scale levels to\n",
            "                        consider (default: 3)\n",
            "  --tracking.kf_node_indices TRACKING.KF_NODE_INDICES\n",
            "                        For Kalman filter: Indices of nodes to track.\n",
            "                        (default: )\n",
            "  --tracking.kf_init_frame_count TRACKING.KF_INIT_FRAME_COUNT\n",
            "                        For Kalman filter: Number of frames to track with\n",
            "                        other tracker. 0 means no Kalman filters will be used.\n",
            "                        (default: 0)\n"
          ]
        }
      ],
      "source": [
        "!sleap-track --help"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MNi260mJuyJ7"
      },
      "source": [
        "To run inference we need a video for which we want predictions, that would be the video we already downloaded.\n",
        "\n",
        "For this demo we'll just get predictions for the first 200 frames (or you can adjust the `--frames` parameter below or remove it to run on the whole video).\n",
        "\n",
        "**Important**: If your video is not named `video.AVI`, change this in the following cell to match the name of your video. If you trained top-down models and not a bottom-up model, see the end of the notebook for how to run inference with the pair of top-down models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CLtjtq9E1Znr",
        "outputId": "39986e00-e5f6-47e5-9219-3fde7d79e1b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:numexpr.utils:NumExpr defaulting to 2 threads.\n",
            "Started inference at: 2022-08-05 02:13:33.530627\n",
            "Args:\n",
            "\u001b[1m{\u001b[0m\n",
            "\u001b[2;32m│   \u001b[0m\u001b[32m'data_path'\u001b[0m: \u001b[32m'video.AVI'\u001b[0m,\n",
            "\u001b[2;32m│   \u001b[0m\u001b[32m'models'\u001b[0m: \u001b[1m[\u001b[0m\u001b[32m'models/baseline_medium_rf.bottomup'\u001b[0m\u001b[1m]\u001b[0m,\n",
            "\u001b[2;32m│   \u001b[0m\u001b[32m'frames'\u001b[0m: \u001b[32m'0-200'\u001b[0m,\n",
            "\u001b[2;32m│   \u001b[0m\u001b[32m'only_labeled_frames'\u001b[0m: \u001b[3;91mFalse\u001b[0m,\n",
            "\u001b[2;32m│   \u001b[0m\u001b[32m'only_suggested_frames'\u001b[0m: \u001b[3;91mFalse\u001b[0m,\n",
            "\u001b[2;32m│   \u001b[0m\u001b[32m'output'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
            "\u001b[2;32m│   \u001b[0m\u001b[32m'no_empty_frames'\u001b[0m: \u001b[3;91mFalse\u001b[0m,\n",
            "\u001b[2;32m│   \u001b[0m\u001b[32m'verbosity'\u001b[0m: \u001b[32m'rich'\u001b[0m,\n",
            "\u001b[2;32m│   \u001b[0m\u001b[32m'video.dataset'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
            "\u001b[2;32m│   \u001b[0m\u001b[32m'video.input_format'\u001b[0m: \u001b[32m'channels_last'\u001b[0m,\n",
            "\u001b[2;32m│   \u001b[0m\u001b[32m'cpu'\u001b[0m: \u001b[3;91mFalse\u001b[0m,\n",
            "\u001b[2;32m│   \u001b[0m\u001b[32m'first_gpu'\u001b[0m: \u001b[3;91mFalse\u001b[0m,\n",
            "\u001b[2;32m│   \u001b[0m\u001b[32m'last_gpu'\u001b[0m: \u001b[3;91mFalse\u001b[0m,\n",
            "\u001b[2;32m│   \u001b[0m\u001b[32m'gpu'\u001b[0m: \u001b[1;36m0\u001b[0m,\n",
            "\u001b[2;32m│   \u001b[0m\u001b[32m'max_edge_length_ratio'\u001b[0m: \u001b[1;36m0.25\u001b[0m,\n",
            "\u001b[2;32m│   \u001b[0m\u001b[32m'dist_penalty_weight'\u001b[0m: \u001b[1;36m1.0\u001b[0m,\n",
            "\u001b[2;32m│   \u001b[0m\u001b[32m'batch_size'\u001b[0m: \u001b[1;36m4\u001b[0m,\n",
            "\u001b[2;32m│   \u001b[0m\u001b[32m'open_in_gui'\u001b[0m: \u001b[3;91mFalse\u001b[0m,\n",
            "\u001b[2;32m│   \u001b[0m\u001b[32m'peak_threshold'\u001b[0m: \u001b[1;36m0.2\u001b[0m,\n",
            "\u001b[2;32m│   \u001b[0m\u001b[32m'tracking.tracker'\u001b[0m: \u001b[32m'flow'\u001b[0m,\n",
            "\u001b[2;32m│   \u001b[0m\u001b[32m'tracking.target_instance_count'\u001b[0m: \u001b[1;36m2\u001b[0m,\n",
            "\u001b[2;32m│   \u001b[0m\u001b[32m'tracking.pre_cull_to_target'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
            "\u001b[2;32m│   \u001b[0m\u001b[32m'tracking.pre_cull_iou_threshold'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
            "\u001b[2;32m│   \u001b[0m\u001b[32m'tracking.post_connect_single_breaks'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
            "\u001b[2;32m│   \u001b[0m\u001b[32m'tracking.clean_instance_count'\u001b[0m: \u001b[1;36m2\u001b[0m,\n",
            "\u001b[2;32m│   \u001b[0m\u001b[32m'tracking.clean_iou_threshold'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
            "\u001b[2;32m│   \u001b[0m\u001b[32m'tracking.similarity'\u001b[0m: \u001b[32m'centroid'\u001b[0m,\n",
            "\u001b[2;32m│   \u001b[0m\u001b[32m'tracking.match'\u001b[0m: \u001b[32m'greedy'\u001b[0m,\n",
            "\u001b[2;32m│   \u001b[0m\u001b[32m'tracking.track_window'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
            "\u001b[2;32m│   \u001b[0m\u001b[32m'tracking.min_new_track_points'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
            "\u001b[2;32m│   \u001b[0m\u001b[32m'tracking.min_match_points'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
            "\u001b[2;32m│   \u001b[0m\u001b[32m'tracking.img_scale'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
            "\u001b[2;32m│   \u001b[0m\u001b[32m'tracking.of_window_size'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
            "\u001b[2;32m│   \u001b[0m\u001b[32m'tracking.of_max_levels'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
            "\u001b[2;32m│   \u001b[0m\u001b[32m'tracking.kf_node_indices'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
            "\u001b[2;32m│   \u001b[0m\u001b[32m'tracking.kf_init_frame_count'\u001b[0m: \u001b[3;35mNone\u001b[0m\n",
            "\u001b[1m}\u001b[0m\n",
            "\n",
            "Versions:\n",
            "SLEAP: 1.2.6\n",
            "TensorFlow: 2.8.2\n",
            "Numpy: 1.21.5\n",
            "Python: 3.7.13\n",
            "OS: Linux-5.4.188+-x86_64-with-Ubuntu-18.04-bionic\n",
            "\n",
            "System:\n",
            "GPUs: 1/1 available\n",
            "  Device: /physical_device:GPU:0\n",
            "         Available: True\n",
            "        Initalized: False\n",
            "     Memory growth: True\n",
            "\n",
            "Video: video.AVI\n",
            "\u001b[2KPredicting... \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m  0%\u001b[0m ETA: \u001b[36m-:--:--\u001b[0m \u001b[31m?\u001b[0m2022-08-05 02:13:41.489034: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -65 } dim { size: -66 } dim { size: -67 } dim { size: 1 } } } inputs { dtype: DT_FLOAT shape { dim { size: -2 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -2 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla T4\" frequency: 1590 num_cores: 40 environment { key: \"architecture\" value: \"7.5\" } environment { key: \"cuda\" value: \"11010\" } environment { key: \"cudnn\" value: \"8005\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 65536 memory_size: 14150270976 bandwidth: 320064000 } outputs { dtype: DT_FLOAT shape { dim { size: -2 } dim { size: -68 } dim { size: -69 } dim { size: 1 } } }\n",
            "\u001b[2KPredicting... \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[35m100%\u001b[0m ETA: \u001b[36m0:00:01\u001b[0m \u001b[31m17.4 FPS\u001b[0m2022-08-05 02:13:58.907489: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -65 } dim { size: -66 } dim { size: -67 } dim { size: 1 } } } inputs { dtype: DT_FLOAT shape { dim { size: -2 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -2 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla T4\" frequency: 1590 num_cores: 40 environment { key: \"architecture\" value: \"7.5\" } environment { key: \"cuda\" value: \"11010\" } environment { key: \"cudnn\" value: \"8005\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 65536 memory_size: 14150270976 bandwidth: 320064000 } outputs { dtype: DT_FLOAT shape { dim { size: -2 } dim { size: -68 } dim { size: -69 } dim { size: 1 } } }\n",
            "\u001b[2KPredicting... \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m ETA: \u001b[36m0:00:00\u001b[0m \u001b[31m2.7 FPS\u001b[0m\n",
            "\u001b[?25hFinished inference at: 2022-08-05 02:14:16.989456\n",
            "Total runtime: 43.45884990692139 secs\n",
            "Predicted frames: 201/201\n",
            "Provenance:\n",
            "\u001b[1m{\u001b[0m\n",
            "\u001b[2;32m│   \u001b[0m\u001b[32m'sleap_version'\u001b[0m: \u001b[32m'1.2.6'\u001b[0m,\n",
            "\u001b[2;32m│   \u001b[0m\u001b[32m'platform'\u001b[0m: \u001b[32m'Linux-5.4.188+-x86_64-with-Ubuntu-18.04-bionic'\u001b[0m,\n",
            "\u001b[2;32m│   \u001b[0m\u001b[32m'command'\u001b[0m: \u001b[32m'/usr/local/bin/sleap-track video.AVI --frames 0-200 --tracking.tracker flow --tracking.similarity centroid --tracking.match greedy --tracking.clean_instance_count 2 --tracking.target_instance_count 2 -m models/baseline_medium_rf.bottomup'\u001b[0m,\n",
            "\u001b[2;32m│   \u001b[0m\u001b[32m'data_path'\u001b[0m: \u001b[32m'video.AVI'\u001b[0m,\n",
            "\u001b[2;32m│   \u001b[0m\u001b[32m'model_paths'\u001b[0m: \u001b[1m[\u001b[0m\u001b[32m'models/baseline_medium_rf.bottomup/training_config.json'\u001b[0m\u001b[1m]\u001b[0m,\n",
            "\u001b[2;32m│   \u001b[0m\u001b[32m'output_path'\u001b[0m: \u001b[32m'video.AVI.predictions.slp'\u001b[0m,\n",
            "\u001b[2;32m│   \u001b[0m\u001b[32m'predictor'\u001b[0m: \u001b[32m'BottomUpPredictor'\u001b[0m,\n",
            "\u001b[2;32m│   \u001b[0m\u001b[32m'total_elapsed'\u001b[0m: \u001b[1;36m43.45884990692139\u001b[0m,\n",
            "\u001b[2;32m│   \u001b[0m\u001b[32m'start_timestamp'\u001b[0m: \u001b[32m'2022-08-05 02:13:33.530627'\u001b[0m,\n",
            "\u001b[2;32m│   \u001b[0m\u001b[32m'finish_timestamp'\u001b[0m: \u001b[32m'2022-08-05 02:14:16.989456'\u001b[0m\n",
            "\u001b[1m}\u001b[0m\n",
            "\n",
            "Saved output: video.AVI.predictions.slp\n"
          ]
        }
      ],
      "source": [
        "!sleap-track video.AVI --frames 0-200 --tracking.tracker flow --tracking.similarity centroid --tracking.match greedy --tracking.clean_instance_count 2 --tracking.target_instance_count 2 -m models/baseline_medium_rf.bottomup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nzObCUToEqwA"
      },
      "source": [
        "When inference is finished, it will save the predictions in a file which can be opened in the GUI as a SLEAP project file. The file will be in the same directory as the video and the filename will be `{video filename}.predictions.slp`.\n",
        "\n",
        "Let's inspect the predictions file:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nPfmNMSt-vS7",
        "outputId": "089c1663-0c23-445b-e44d-239184780be7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:numexpr.utils:NumExpr defaulting to 2 threads.\n",
            "Labeled frames: 201\n",
            "Tracks: 2\n",
            "Video files:\n",
            "  video.AVI\n",
            "    labeled frames: 201\n",
            "    labeled frames from 0 to 200\n",
            "    user labeled frames: 0\n",
            "    tracks: 2\n",
            "    max instances in frame: 2\n",
            "Total user labeled frames: 0\n",
            "\n",
            "Provenance:\n",
            "  sleap_version: 1.2.6\n",
            "  platform: Linux-5.4.188+-x86_64-with-Ubuntu-18.04-bionic\n",
            "  command: /usr/local/bin/sleap-track video.AVI --frames 0-200 --tracking.tracker flow --tracking.similarity centroid --tracking.match greedy --tracking.clean_instance_count 2 --tracking.target_instance_count 2 -m models/baseline_medium_rf.bottomup\n",
            "  data_path: video.AVI\n",
            "  model_paths: ['models/baseline_medium_rf.bottomup/training_config.json']\n",
            "  output_path: video.AVI.predictions.slp\n",
            "  predictor: BottomUpPredictor\n",
            "  total_elapsed: 43.45884990692139\n",
            "  start_timestamp: 2022-08-05 02:13:33.530627\n",
            "  finish_timestamp: 2022-08-05 02:14:16.989456\n",
            "  args: {'data_path': 'video.AVI', 'models': ['models/baseline_medium_rf.bottomup'], 'frames': '0-200', 'only_labeled_frames': False, 'only_suggested_frames': False, 'output': None, 'no_empty_frames': False, 'verbosity': 'rich', 'video.dataset': None, 'video.input_format': 'channels_last', 'cpu': False, 'first_gpu': False, 'last_gpu': False, 'gpu': 0, 'max_edge_length_ratio': 0.25, 'dist_penalty_weight': 1.0, 'batch_size': 4, 'open_in_gui': False, 'peak_threshold': 0.2, 'tracking.tracker': 'flow', 'tracking.target_instance_count': 2, 'tracking.pre_cull_to_target': None, 'tracking.pre_cull_iou_threshold': None, 'tracking.post_connect_single_breaks': None, 'tracking.clean_instance_count': 2, 'tracking.clean_iou_threshold': None, 'tracking.similarity': 'centroid', 'tracking.match': 'greedy', 'tracking.track_window': None, 'tracking.min_new_track_points': None, 'tracking.min_match_points': None, 'tracking.img_scale': None, 'tracking.of_window_size': None, 'tracking.of_max_levels': None, 'tracking.kf_node_indices': None, 'tracking.kf_init_frame_count': None}\n"
          ]
        }
      ],
      "source": [
        "!sleap-inspect video.AVI.predictions.slp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LoJ2kNBK-w6k"
      },
      "source": [
        "# Creating a video with the predictions\n",
        "\n",
        "Now that we have ran training and inference we are ready to create a video to see how it looks. Run the cell below to do so.\n",
        "\n",
        "**Important:** This is a feature from SLEAP v1.2.4 so make sure you have a version equal than or higher to that. The --frames parameter will create a video for that set of frames. If you wish to render the whole video, remove this --frames 0-200.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TbR7yHGSbJs7",
        "outputId": "cd9c7677-1334-407b-a66b-32f29f5531ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:numexpr.utils:NumExpr defaulting to 2 threads.\n",
            "Saving config: /root/.sleap/1.2.6/preferences.yaml\n",
            "Writing video with 201 frame images...\n",
            "INFO:sleap.io.visuals:Chunks: 4, chunk size: 64\n",
            "Finished 64 frames in 2.3033236709998164 s, fps = 27.78593421575838, approx 4.930552233233982 s remaining\n",
            "Finished 128 frames in 2.7496055709998473 s, fps = 46.55213145842404, approx 1.5681344272108504 s remaining\n",
            "Finished 192 frames in 3.083332968999912 s, fps = 62.2702776282627, approx 0.14453123292187087 s remaining\n",
            "Finished 201 frames in 3.1304715759997634 s, fps = 64.20757867312933, approx 0.0 s remaining\n",
            "Done in 3.173448206000103 s, fps = 63.33804333720186.\n",
            "Video saved as: video.AVI.predictions.slp.avi\n"
          ]
        }
      ],
      "source": [
        "!sleap-render video.AVI.predictions.slp --frames 0-200"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7vA47k0VybPf"
      },
      "source": [
        "The file will be saved in the root folder as video.AVI.predictions.slp.avi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qW-NoJOFvYHM"
      },
      "source": [
        "## Inference with top-down models\n",
        "\n",
        "If you trained the pair of models needed for top-down inference, you can call `sleap-track` with `-m path/to/model` for each model, like so:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QPKnMc1qvim7"
      },
      "outputs": [],
      "source": [
        "!sleap-track video.AVI --frames 0-200 --tracking.tracker flow --tracking.similarity centroid --tracking.match greedy --tracking.clean_instance_count 2 -m models/baseline_medium_rf.topdown -m models/baseline.centroid"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "include_colab_link": true,
      "name": "Training and inference using Google Drive",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.8.10 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
